% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/import.R
\name{dbbind.insert}
\alias{dbbind.insert}
\title{This is the top-table level inserting function which attempts, be default to
write source data to the destination in chunks of \code{chunk.size} rows. It
manages errors in the chunk insert by moving to a row-wise insert for that
particular chunk. A smaller \code{chunk.size} will result in slower inserts
for data without foreign key violations (or other errors) but decreasing
\code{chunk.size} can speed up inserts for data where foreign key issues
are common.}
\usage{
dbbind.insert(
  update,
  schema,
  table,
  table.name,
  cols,
  cast,
  log,
  verbose = FALSE,
  chunk.size = 1000
)
}
\arguments{
\item{update}{logical. A flag that instructs the function to construct an
UPSERT statement instead of an INSERT statement.}

\item{schema}{A string. The name of the schema in the destination.}

\item{table}{A tibble containing the source data to be inserted.}

\item{table.name}{A name of the table in the destination for which to build
the INSERT statement.}

\item{cols}{A string vector containing the names of columns to use for
the insert statement.}

\item{cast}{A logical vector telling the function whether to encapsulate the
parameter in the SQL in a CAST function, hopefully mitigating type errors.}

\item{log}{A string file path location of the log file to write
results to.}

\item{verbose}{logical. A flag telling the function to be more verbose in
its messaging.}

\item{chunk.size}{An integer.This tells the function how many rows to
attempt to insert at once. Failure on a chunk will cause the function
to default to row-wise inserts for the entire chunk.}
}
\value{
The number of rows affected by the insert.
}
\description{
This is the top-table level inserting function which attempts, be default to
write source data to the destination in chunks of \code{chunk.size} rows. It
manages errors in the chunk insert by moving to a row-wise insert for that
particular chunk. A smaller \code{chunk.size} will result in slower inserts
for data without foreign key violations (or other errors) but decreasing
\code{chunk.size} can speed up inserts for data where foreign key issues
are common.
}
